{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309fbb0f-da08-4706-848f-ef81c1b952b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, random_split, default_collate\n",
    "from triplet_loss import *\n",
    "from Siamese import SiameseModel, QuadrupletModel\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.loggers import wandb\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from utils import TextDataset, AdvDataset, load_feature_extractor,get_results\n",
    "from transformers import RobertaTokenizer, RobertaConfig, RobertaForSequenceClassification\n",
    "from itertools import cycle\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import wandb\n",
    "import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2316003c-ea32-4a6a-8e77-86f9c7f07cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Input Reflector')\n",
    "parser.add_argument('--sia_path', default='veweew/inputReflector/model-l1kr6pgx:v6', type=str, help='Path for SIA model, you can use local ckpt path or wandb cloud checkpoint ID')\n",
    "parser.add_argument('--quad_path', default='veweew/inputReflector/model-3v67c2u7:v1', type=str, help='Path for QUAD model, you can use local ckpt path or wandb cloud checkpoint ID')\n",
    "parser.add_argument('--valid_set', default='valid.jsonl', type=str, help='Path to the validation set')\n",
    "parser.add_argument('--train_set', default='train.jsonl', type=str, help='Path to the training set')\n",
    "parser.add_argument('--test_set', default='test.jsonl', type=str, help='Path to the test set')\n",
    "parser.add_argument('--pretrained_model', default='model.bin', type=str, help='Path to the pretrained model')\n",
    "parser.add_argument('--sia_train_embedding', type=str, help='Optional, path to SIA training embeddings')\n",
    "parser.add_argument('--sia_valid_embedding', type=str, help='Optional, Path to SIA validation embeddings')\n",
    "parser.add_argument('--sia_test_embedding',  type=str, help='Optional, Path to SIA test embeddings')\n",
    "parser.add_argument('--quad_train_embedding', type=str, help='Optional, Path to QUAD training embeddings')\n",
    "parser.add_argument('--quad_test_embedding', type=str, help='Optional, Path to QUAD test embeddings')\n",
    "parser.add_argument('--batch_size', default=32, type=int, help='Batch size')\n",
    "parser.add_argument('--t_in', default=95, type=int, help='t_in parameter')\n",
    "parser.add_argument('--t_out', default=98, type=int, help='t_out parameter')\n",
    "\n",
    "default_args_list = [\n",
    "    '--sia_path', 'veweew/inputReflector/model-l1kr6pgx:v6',\n",
    "    '--quad_path', 'veweew/inputReflector/model-3v67c2u7:v1',\n",
    "    '--valid_set', 'valid.jsonl',\n",
    "    '--train_set', 'train.jsonl',\n",
    "    '--test_set', 'test.jsonl',\n",
    "    '--pretrained_model', 'model.bin',\n",
    "    '--batch_size', '32',\n",
    "    '--t_in', '95',\n",
    "    '--t_out', '98'\n",
    "]\n",
    "\n",
    "args = parser.parse_args(default_args_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ea9d61-1b37-47cd-9c74-ad431a8876bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not args.sia_path.endswith('.ckpt'):\n",
    "    run = wandb.init()\n",
    "    artifact = run.use_artifact(args.sia_path, type='model')\n",
    "    artifact_dir = artifact.download()\n",
    "    args.sia_path = Path(artifact_dir) / \"model.ckpt\"\n",
    "\n",
    "tokenizer, feature_extractor = load_feature_extractor(args.pretrained_model)\n",
    "block_size = tokenizer.max_len_single_sentence\n",
    "model = SiameseModel(feature_extractor)\n",
    "model.load_from_checkpoint(args.sia_path)\n",
    "model.to('cuda')\n",
    "model.eval()\n",
    "print(\"Sia Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c3d9dc-1256-406c-83c0-7ffe554c55c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = TextDataset(tokenizer, block_size, args.test_set)\n",
    "train_set = TextDataset(tokenizer, block_size, args.train_set)\n",
    "valid_set = TextDataset(tokenizer, block_size, args.valid_set)\n",
    "\n",
    "test_loader = DataLoader(test_set, batch_size = args.batch_size)\n",
    "train_loader = DataLoader(train_set, batch_size = args.batch_size)\n",
    "valid_loader = DataLoader(valid_set, batch_size = args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c747c7-5996-4d07-af82-0c4c49d5415f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.sia_train_embedding:\n",
    "    with open(args.sia_train_embedding, 'rb') as f:\n",
    "        train_embedding_vectors = np.load(f)\n",
    "else:\n",
    "    train_embeddings = []\n",
    "    for train in tqdm(train_loader):\n",
    "        with torch.no_grad():\n",
    "            output = model(train[0])\n",
    "            train_embeddings.append(output.cpu())\n",
    "    train_embedding_vectors = torch.cat(train_embeddings, dim=0).detach().numpy()\n",
    "    with open('sia_train_embeddings.npy', 'wb') as f:\n",
    "        np.save(f, train_embedding_vectors)\n",
    "\n",
    "if args.sia_valid_embedding:\n",
    "    with open(args.sia_valid_embedding, 'rb') as f:\n",
    "        valid_embedding_vectors = np.load(f)\n",
    "else:\n",
    "    valid_embeddings = []\n",
    "    for valid in tqdm(valid_loader):\n",
    "        with torch.no_grad():\n",
    "            output = model(valid[0])\n",
    "            valid_embeddings.append(output.cpu())\n",
    "    valid_embedding_vectors = torch.cat(valid_embeddings, dim=0).detach().numpy()\n",
    "    with open('sia_valid_embeddings.npy', 'wb') as f:\n",
    "        np.save(f, valid_embedding_vectors)\n",
    "\n",
    "if args.sia_test_embedding:\n",
    "    with open(args.sia_test_embedding, 'rb') as f:\n",
    "        test_embedding_vectors = np.load(f)    \n",
    "else:\n",
    "    test_embeddings = []\n",
    "    for test in tqdm(test_loader):\n",
    "        with torch.no_grad():\n",
    "            output = model(test[0])\n",
    "            test_embeddings.append(output.cpu())\n",
    "    test_embedding_vectors = torch.cat(test_embeddings, dim=0).detach().numpy()\n",
    "    with open('sia_test_embeddings.npy', 'wb') as f:\n",
    "        np.save(f, test_embedding_vectors)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d45673-d811-4dbb-92c2-5731e0ca162f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dist(x, trains):\n",
    "    # Calculate distances\n",
    "    distances = np.empty(shape=(x.shape[0],))\n",
    "    index = []\n",
    "    for i in tqdm(range(x.shape[0])):\n",
    "        dises = np.sqrt(np.sum(np.asarray(x[i] - trains) ** 2, axis=1))\n",
    "        distance = np.sort(dises)[0]\n",
    "        index.append(np.argsort(dises)[0])\n",
    "        distances.put(i, distance)\n",
    "\n",
    "    return distances, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a876c906-69e8-4ca2-ab0d-fbbe3be84a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_distance,_ = calc_dist(valid_embedding_vectors, train_embedding_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58d7576-a30f-4887-bae8-2db92f43cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Minimal Distance for out-of-distribution examples\n",
    "threshold_out = np.percentile(val_distance, args.t_out)\n",
    "#Maximum Distances for in-distribution examples\n",
    "threshold_in = np.percentile(val_distance, args.t_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8da41dc-3ca5-4b15-b4de-587af97a6d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_distance, _ = calc_dist(test_embedding_vectors, train_embedding_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad193f23-9acf-453d-b986-a2cc540ac02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labels Generated by Distribution Analyzer\n",
    "out_of_distribution_examples = test_distance > threshold_out\n",
    "in_distribution_examples = test_distance < threshold_in\n",
    "deviating_examples = ~(out_of_distribution_examples | in_distribution_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c708dd7-60c9-44ad-aebd-18c6f4169c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, labels = get_results(feature_extractor, test_set, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1aacec-c14b-42d8-a69a-0efbe2b50436",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(torch.tensor(~in_distribution_examples) & (pred != labels)) / torch.sum((pred != labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be824687-ccbd-4b07-82e8-0eebb4ef2b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not args.quad_path.endswith('.ckpt'):\n",
    "    run = wandb.init()\n",
    "    artifact = run.use_artifact(args.quad_path, type='model')\n",
    "    artifact_dir = artifact.download()\n",
    "    args.quad_path = Path(artifact_dir) / \"model.ckpt\"\n",
    "model = QuadrupletModel(feature_extractor)\n",
    "model.load_from_checkpoint(args.quad_path)\n",
    "model.to('cuda')\n",
    "model.eval()\n",
    "print('Quad Model Loaded!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7db4258-08ae-493b-88f1-6f3752cbdb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, Revise the output for deviating examples\n",
    "if args.quad_train_embedding:\n",
    "    with open(args.quad_train_embedding, 'rb') as f:\n",
    "        train_embedding_vectors = np.load(f)\n",
    "else:\n",
    "    train_embeddings = []\n",
    "    for train in tqdm(train_loader):\n",
    "        with torch.no_grad():\n",
    "            output = model(train[0])\n",
    "            train_embeddings.append(output.cpu())\n",
    "    train_embedding_vectors = torch.cat(train_embeddings, dim=0).detach().numpy()\n",
    "    with open('quad_train_embeddings.npy', 'wb') as f:\n",
    "        np.save(f, train_embedding_vectors)\n",
    "\n",
    "if args.quad_test_embedding:\n",
    "    with open(args.quad_test_embedding, 'rb') as f:\n",
    "        test_embedding_vectors = np.load(f)    \n",
    "else:\n",
    "    test_embeddings = []\n",
    "    for test in tqdm(test_loader):\n",
    "        with torch.no_grad():\n",
    "            output = model(test[0])\n",
    "            test_embeddings.append(output.cpu())\n",
    "    test_embedding_vectors = torch.cat(test_embeddings, dim=0).detach().numpy()\n",
    "    with open('quad_test_embeddings.npy', 'wb') as f:\n",
    "        np.save(f, test_embedding_vectors)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe99251-cefb-497a-894c-0bfeb58b7a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis, idx = calc_dist(test_embedding_vectors, train_embedding_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fbdb83-d8a1-4893-9f15-ba5923034399",
   "metadata": {},
   "outputs": [],
   "source": [
    "revised_prediction = pred.clone()\n",
    "revised = []\n",
    "for i in np.nonzero(deviating_examples)[0]:\n",
    "    revised.append(train_set[idx[i]][1])\n",
    "    \n",
    "    \n",
    "#Revised Prediction by InputReflector\n",
    "revised_prediction[deviating_examples] = torch.stack(revised,dim=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
